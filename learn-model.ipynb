{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We plan to create 2 types of models, compare and then choose the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df_mean = pd.read_csv('assets/cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>minutes_past</th>\n",
       "      <th>radardist_km</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Ref_5x5_10th</th>\n",
       "      <th>Ref_5x5_50th</th>\n",
       "      <th>Ref_5x5_90th</th>\n",
       "      <th>RefComposite</th>\n",
       "      <th>RefComposite_5x5_10th</th>\n",
       "      <th>RefComposite_5x5_50th</th>\n",
       "      <th>...</th>\n",
       "      <th>RhoHV_5x5_90th</th>\n",
       "      <th>Zdr</th>\n",
       "      <th>Zdr_5x5_10th</th>\n",
       "      <th>Zdr_5x5_50th</th>\n",
       "      <th>Zdr_5x5_90th</th>\n",
       "      <th>Kdp</th>\n",
       "      <th>Kdp_5x5_10th</th>\n",
       "      <th>Kdp_5x5_50th</th>\n",
       "      <th>Kdp_5x5_90th</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29.833333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.625</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>17.375</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>20.375000</td>\n",
       "      <td>22.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.119792</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>-0.288187</td>\n",
       "      <td>-1.448893</td>\n",
       "      <td>-0.319096</td>\n",
       "      <td>1.116661</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.162014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28.153846</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.600</td>\n",
       "      <td>20.071429</td>\n",
       "      <td>25.800</td>\n",
       "      <td>30.269231</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>21.090909</td>\n",
       "      <td>25.115385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015833</td>\n",
       "      <td>-1.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.515625</td>\n",
       "      <td>7.029999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329994</td>\n",
       "      <td>4.064002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>28.714286</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>774.700440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  minutes_past  radardist_km     Ref  Ref_5x5_10th  Ref_5x5_50th  \\\n",
       "0   1     29.833333          10.0   0.000      0.000000         0.000   \n",
       "1   2     29.083333           2.0  16.625     13.666667        17.375   \n",
       "2   3     30.750000          10.0   0.000      0.000000         0.000   \n",
       "3   4     28.153846           9.0  26.600     20.071429        25.800   \n",
       "4   5     28.714286          13.0   0.000      0.000000         0.000   \n",
       "\n",
       "   Ref_5x5_90th  RefComposite  RefComposite_5x5_10th  RefComposite_5x5_50th  \\\n",
       "0      0.000000      0.000000               0.000000               0.000000   \n",
       "1     21.333333     22.666667              20.375000              22.916667   \n",
       "2      8.500000      0.000000               0.000000               0.000000   \n",
       "3     30.269231     26.666667              21.090909              25.115385   \n",
       "4      0.000000      0.000000               0.000000               0.000000   \n",
       "\n",
       "   ...  RhoHV_5x5_90th       Zdr  Zdr_5x5_10th  Zdr_5x5_50th  Zdr_5x5_90th  \\\n",
       "0  ...        0.000000  0.000000      0.000000      0.000000      0.000000   \n",
       "1  ...        1.000000  0.380208      0.119792      0.416667      0.781250   \n",
       "2  ...        0.801667  0.000000      0.000000      0.000000      2.062500   \n",
       "3  ...        1.015833 -1.125000      0.000000      0.500000      1.515625   \n",
       "4  ...        0.000000  0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "        Kdp  Kdp_5x5_10th  Kdp_5x5_50th  Kdp_5x5_90th    Expected  \n",
       "0  0.000000      0.000000      0.000000      0.000000    0.254000  \n",
       "1 -0.288187     -1.448893     -0.319096      1.116661    1.016001  \n",
       "2  0.000000      0.000000      0.000000      0.000000   26.162014  \n",
       "3  7.029999      0.000000      0.000000      6.329994    4.064002  \n",
       "4  0.000000      0.000000      0.000000      0.000000  774.700440  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_mean.info()\n",
    "df_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data frames to be the inputs of the skit model\n",
    "X = df_mean.iloc[:, :-1]\n",
    "Y = df_mean.iloc[:, 23:]\n",
    "Y = Y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Scaling data frame\n",
    "# scaling X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/introduction/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/introduction/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/introduction/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/introduction/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/introduction/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/introduction/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "clf = RandomForestRegressor(random_state=42, max_depth=35, n_jobs=-1)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 14802.15123722491\n",
      "Mean Absolute Error (MAE): 32.486672054971365\n",
      "R-squared: 0.5258692789469954\n"
     ]
    }
   ],
   "source": [
    "# Get predictions and evaluate performance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Predicting values using the trained model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate regression metrics\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "# Print results \n",
    "# # MSE: A low MSE indicates that the model predicts the actual values more accurately.\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "# MAE: A low MAE indicates that the average error between predicted and actual values is small.\n",
    "# In general, an MAE as close to 0 as possible is sought. \n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "# R-squared: An R-squared value close to 1 \n",
    "# indicates that the model explains a large proportion of the variability in the data.\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "rfr_m = [mse, mae, r2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df_mean = pd.read_csv('assets/cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.143831e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.681348e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.774018e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.540001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.016001e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.302002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.939799e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Expected\n",
       "count  1.143831e+06\n",
       "mean   3.681348e+01\n",
       "std    1.774018e+02\n",
       "min    1.000000e-02\n",
       "25%    2.540001e-01\n",
       "50%    1.016001e+00\n",
       "75%    3.302002e+00\n",
       "max    1.939799e+03"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set data frames to be the inputs of the skit model\n",
    "X = df_mean.iloc[:, :-1]\n",
    "Y = df_mean.iloc[:, 23:]\n",
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Scaling data frame\n",
    "# scaling X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Ensure Y_train is a 2D array\n",
    "Y_train = np.reshape(Y_train, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029447, 23) 1029447 <class 'numpy.ndarray'>\n",
      "(1029447, 1) 1029447 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, len(X_train), type(X_train))\n",
    "print(Y_train.shape, len(Y_train), type(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/my_project/tuner0.json\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaforerof/.pyenv/versions/3.11.9/envs/introduction/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2ms/step - loss: 29509.4121 - mean_squared_error: 29509.4121 - val_loss: 28916.2383 - val_mean_squared_error: 28916.2383\n",
      "Epoch 2/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2ms/step - loss: 27883.9473 - mean_squared_error: 27883.9473 - val_loss: 28247.7734 - val_mean_squared_error: 28247.7734\n",
      "Epoch 3/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 27724.7617 - mean_squared_error: 27724.7617 - val_loss: 27757.6895 - val_mean_squared_error: 27757.6895\n",
      "Epoch 4/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 26808.3613 - mean_squared_error: 26808.3613 - val_loss: 27538.3965 - val_mean_squared_error: 27538.3965\n",
      "Epoch 5/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 27236.1680 - mean_squared_error: 27236.1680 - val_loss: 27415.7539 - val_mean_squared_error: 27415.7539\n",
      "Epoch 6/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 26719.1426 - mean_squared_error: 26719.1426 - val_loss: 27441.3027 - val_mean_squared_error: 27441.3027\n",
      "Epoch 7/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 27018.9941 - mean_squared_error: 27018.9941 - val_loss: 27214.6816 - val_mean_squared_error: 27214.6816\n",
      "Epoch 8/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step - loss: 26805.9297 - mean_squared_error: 26805.9297 - val_loss: 27176.4023 - val_mean_squared_error: 27176.4023\n",
      "Epoch 9/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1ms/step - loss: 26823.4160 - mean_squared_error: 26823.4160 - val_loss: 27130.7695 - val_mean_squared_error: 27130.7695\n",
      "Epoch 10/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26310.5117 - mean_squared_error: 26310.5117 - val_loss: 27165.6797 - val_mean_squared_error: 27165.6797\n",
      "Epoch 11/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26765.6836 - mean_squared_error: 26765.6836 - val_loss: 27092.2207 - val_mean_squared_error: 27092.2207\n",
      "Epoch 12/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26356.0801 - mean_squared_error: 26356.0801 - val_loss: 26994.4902 - val_mean_squared_error: 26994.4902\n",
      "Epoch 13/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26147.1211 - mean_squared_error: 26147.1211 - val_loss: 26952.0664 - val_mean_squared_error: 26952.0664\n",
      "Epoch 14/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26579.6641 - mean_squared_error: 26579.6641 - val_loss: 27086.8242 - val_mean_squared_error: 27086.8242\n",
      "Epoch 15/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26213.2852 - mean_squared_error: 26213.2852 - val_loss: 26954.5527 - val_mean_squared_error: 26954.5527\n",
      "Epoch 16/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26632.6133 - mean_squared_error: 26632.6133 - val_loss: 26917.1973 - val_mean_squared_error: 26917.1973\n",
      "Epoch 17/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26153.8145 - mean_squared_error: 26153.8145 - val_loss: 27012.3555 - val_mean_squared_error: 27012.3555\n",
      "Epoch 18/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26027.6992 - mean_squared_error: 26027.6992 - val_loss: 26885.4180 - val_mean_squared_error: 26885.4180\n",
      "Epoch 19/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26321.4141 - mean_squared_error: 26321.4141 - val_loss: 27000.8418 - val_mean_squared_error: 27000.8418\n",
      "Epoch 20/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26363.8672 - mean_squared_error: 26363.8672 - val_loss: 26862.2090 - val_mean_squared_error: 26862.2090\n",
      "Epoch 21/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26022.0820 - mean_squared_error: 26022.0820 - val_loss: 27114.6855 - val_mean_squared_error: 27114.6855\n",
      "Epoch 22/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26109.6191 - mean_squared_error: 26109.6191 - val_loss: 27019.5078 - val_mean_squared_error: 27019.5078\n",
      "Epoch 23/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26125.3496 - mean_squared_error: 26125.3496 - val_loss: 27198.1562 - val_mean_squared_error: 27198.1562\n",
      "Epoch 24/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26140.8496 - mean_squared_error: 26140.8496 - val_loss: 26851.5449 - val_mean_squared_error: 26851.5449\n",
      "Epoch 25/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 26057.5547 - mean_squared_error: 26057.5547 - val_loss: 27081.7109 - val_mean_squared_error: 27081.7109\n",
      "Epoch 26/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26115.4023 - mean_squared_error: 26115.4023 - val_loss: 26829.6777 - val_mean_squared_error: 26829.6777\n",
      "Epoch 27/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26091.9297 - mean_squared_error: 26091.9297 - val_loss: 26818.1152 - val_mean_squared_error: 26818.1152\n",
      "Epoch 28/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26051.7773 - mean_squared_error: 26051.7773 - val_loss: 26773.6816 - val_mean_squared_error: 26773.6816\n",
      "Epoch 29/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26223.0645 - mean_squared_error: 26223.0645 - val_loss: 26803.5996 - val_mean_squared_error: 26803.5996\n",
      "Epoch 30/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26076.9668 - mean_squared_error: 26076.9668 - val_loss: 26830.0391 - val_mean_squared_error: 26830.0391\n",
      "Epoch 31/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25801.5605 - mean_squared_error: 25801.5605 - val_loss: 26902.2070 - val_mean_squared_error: 26902.2070\n",
      "Epoch 32/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25975.6953 - mean_squared_error: 25975.6953 - val_loss: 26941.1328 - val_mean_squared_error: 26941.1328\n",
      "Epoch 33/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25773.4238 - mean_squared_error: 25773.4238 - val_loss: 26922.8887 - val_mean_squared_error: 26922.8887\n",
      "Epoch 34/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26192.2285 - mean_squared_error: 26192.2285 - val_loss: 26793.5840 - val_mean_squared_error: 26793.5840\n",
      "Epoch 35/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26040.7305 - mean_squared_error: 26040.7305 - val_loss: 26842.0762 - val_mean_squared_error: 26842.0762\n",
      "Epoch 36/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26139.8340 - mean_squared_error: 26139.8340 - val_loss: 26762.5176 - val_mean_squared_error: 26762.5176\n",
      "Epoch 37/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26038.7070 - mean_squared_error: 26038.7070 - val_loss: 26742.3262 - val_mean_squared_error: 26742.3262\n",
      "Epoch 38/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26016.6523 - mean_squared_error: 26016.6523 - val_loss: 26690.8301 - val_mean_squared_error: 26690.8301\n",
      "Epoch 39/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25849.3789 - mean_squared_error: 25849.3789 - val_loss: 26755.4238 - val_mean_squared_error: 26755.4238\n",
      "Epoch 40/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25990.0957 - mean_squared_error: 25990.0957 - val_loss: 26750.1055 - val_mean_squared_error: 26750.1055\n",
      "Epoch 41/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25860.7578 - mean_squared_error: 25860.7578 - val_loss: 26731.7988 - val_mean_squared_error: 26731.7988\n",
      "Epoch 42/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25933.4844 - mean_squared_error: 25933.4844 - val_loss: 26751.9531 - val_mean_squared_error: 26751.9531\n",
      "Epoch 43/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25547.8691 - mean_squared_error: 25547.8691 - val_loss: 26719.6211 - val_mean_squared_error: 26719.6211\n",
      "Epoch 44/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25700.0000 - mean_squared_error: 25700.0000 - val_loss: 26763.8398 - val_mean_squared_error: 26763.8398\n",
      "Epoch 45/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25689.3496 - mean_squared_error: 25689.3496 - val_loss: 26697.2520 - val_mean_squared_error: 26697.2520\n",
      "Epoch 46/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25677.7227 - mean_squared_error: 25677.7227 - val_loss: 26738.9961 - val_mean_squared_error: 26738.9961\n",
      "Epoch 47/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25604.2090 - mean_squared_error: 25604.2090 - val_loss: 26680.6738 - val_mean_squared_error: 26680.6738\n",
      "Epoch 48/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25697.5547 - mean_squared_error: 25697.5547 - val_loss: 26735.0957 - val_mean_squared_error: 26735.0957\n",
      "Epoch 49/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25858.3359 - mean_squared_error: 25858.3359 - val_loss: 26693.8164 - val_mean_squared_error: 26693.8164\n",
      "Epoch 50/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 26135.8281 - mean_squared_error: 26135.8281 - val_loss: 26748.1484 - val_mean_squared_error: 26748.1484\n",
      "Epoch 51/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25960.9473 - mean_squared_error: 25960.9473 - val_loss: 26700.0430 - val_mean_squared_error: 26700.0430\n",
      "Epoch 52/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25809.6680 - mean_squared_error: 25809.6680 - val_loss: 26707.6035 - val_mean_squared_error: 26707.6035\n",
      "Epoch 53/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25957.9766 - mean_squared_error: 25957.9766 - val_loss: 26799.3477 - val_mean_squared_error: 26799.3477\n",
      "Epoch 54/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25681.2637 - mean_squared_error: 25681.2637 - val_loss: 26754.6016 - val_mean_squared_error: 26754.6016\n",
      "Epoch 55/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25876.1797 - mean_squared_error: 25876.1797 - val_loss: 26701.0254 - val_mean_squared_error: 26701.0254\n",
      "Epoch 56/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25887.0371 - mean_squared_error: 25887.0371 - val_loss: 26690.1426 - val_mean_squared_error: 26690.1426\n",
      "Epoch 57/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25762.0020 - mean_squared_error: 25762.0020 - val_loss: 27348.7031 - val_mean_squared_error: 27348.7031\n",
      "Epoch 58/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25885.0312 - mean_squared_error: 25885.0312 - val_loss: 26700.9531 - val_mean_squared_error: 26700.9531\n",
      "Epoch 59/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25571.8027 - mean_squared_error: 25571.8027 - val_loss: 26670.7578 - val_mean_squared_error: 26670.7578\n",
      "Epoch 60/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25678.6309 - mean_squared_error: 25678.6309 - val_loss: 26588.6328 - val_mean_squared_error: 26588.6328\n",
      "Epoch 61/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25791.1191 - mean_squared_error: 25791.1191 - val_loss: 26661.1328 - val_mean_squared_error: 26661.1328\n",
      "Epoch 62/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25715.0020 - mean_squared_error: 25715.0020 - val_loss: 26677.6914 - val_mean_squared_error: 26677.6914\n",
      "Epoch 63/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25449.1777 - mean_squared_error: 25449.1777 - val_loss: 26704.5840 - val_mean_squared_error: 26704.5840\n",
      "Epoch 64/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25712.1621 - mean_squared_error: 25712.1621 - val_loss: 26626.0410 - val_mean_squared_error: 26626.0410\n",
      "Epoch 65/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25477.2012 - mean_squared_error: 25477.2012 - val_loss: 26620.9902 - val_mean_squared_error: 26620.9902\n",
      "Epoch 66/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25585.6016 - mean_squared_error: 25585.6016 - val_loss: 26733.4316 - val_mean_squared_error: 26733.4316\n",
      "Epoch 67/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25736.0762 - mean_squared_error: 25736.0762 - val_loss: 26612.7773 - val_mean_squared_error: 26612.7773\n",
      "Epoch 68/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25577.0938 - mean_squared_error: 25577.0938 - val_loss: 26673.5957 - val_mean_squared_error: 26673.5957\n",
      "Epoch 69/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25723.2207 - mean_squared_error: 25723.2207 - val_loss: 26685.6328 - val_mean_squared_error: 26685.6328\n",
      "Epoch 70/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25682.3535 - mean_squared_error: 25682.3535 - val_loss: 26668.1992 - val_mean_squared_error: 26668.1992\n",
      "Epoch 71/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25496.2910 - mean_squared_error: 25496.2910 - val_loss: 26658.9062 - val_mean_squared_error: 26658.9062\n",
      "Epoch 72/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 25969.1953 - mean_squared_error: 25969.1953 - val_loss: 26580.4551 - val_mean_squared_error: 26580.4551\n",
      "Epoch 73/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25745.6367 - mean_squared_error: 25745.6367 - val_loss: 26588.6680 - val_mean_squared_error: 26588.6680\n",
      "Epoch 74/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25377.3008 - mean_squared_error: 25377.3008 - val_loss: 26621.2441 - val_mean_squared_error: 26621.2441\n",
      "Epoch 75/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25922.9023 - mean_squared_error: 25922.9023 - val_loss: 26653.3516 - val_mean_squared_error: 26653.3516\n",
      "Epoch 76/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25589.3984 - mean_squared_error: 25589.3984 - val_loss: 26578.8555 - val_mean_squared_error: 26578.8555\n",
      "Epoch 77/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25445.8398 - mean_squared_error: 25445.8398 - val_loss: 26582.9707 - val_mean_squared_error: 26582.9707\n",
      "Epoch 78/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25454.4941 - mean_squared_error: 25454.4941 - val_loss: 26522.2734 - val_mean_squared_error: 26522.2734\n",
      "Epoch 79/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25988.7676 - mean_squared_error: 25988.7676 - val_loss: 26686.6211 - val_mean_squared_error: 26686.6211\n",
      "Epoch 80/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25617.3730 - mean_squared_error: 25617.3730 - val_loss: 26563.5547 - val_mean_squared_error: 26563.5547\n",
      "Epoch 81/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25221.0879 - mean_squared_error: 25221.0879 - val_loss: 26597.7793 - val_mean_squared_error: 26597.7793\n",
      "Epoch 82/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25319.2754 - mean_squared_error: 25319.2754 - val_loss: 26745.8770 - val_mean_squared_error: 26745.8770\n",
      "Epoch 83/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25635.2363 - mean_squared_error: 25635.2363 - val_loss: 26515.9434 - val_mean_squared_error: 26515.9434\n",
      "Epoch 84/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25671.4785 - mean_squared_error: 25671.4785 - val_loss: 26547.8926 - val_mean_squared_error: 26547.8926\n",
      "Epoch 85/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25323.2891 - mean_squared_error: 25323.2891 - val_loss: 26588.1406 - val_mean_squared_error: 26588.1406\n",
      "Epoch 86/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25591.4414 - mean_squared_error: 25591.4414 - val_loss: 26631.0703 - val_mean_squared_error: 26631.0703\n",
      "Epoch 87/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25696.6465 - mean_squared_error: 25696.6465 - val_loss: 26552.0176 - val_mean_squared_error: 26552.0176\n",
      "Epoch 88/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25516.0977 - mean_squared_error: 25516.0977 - val_loss: 26548.7363 - val_mean_squared_error: 26548.7363\n",
      "Epoch 89/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25803.7070 - mean_squared_error: 25803.7070 - val_loss: 26578.9473 - val_mean_squared_error: 26578.9473\n",
      "Epoch 90/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25594.4160 - mean_squared_error: 25594.4160 - val_loss: 26479.1211 - val_mean_squared_error: 26479.1211\n",
      "Epoch 91/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25590.5410 - mean_squared_error: 25590.5410 - val_loss: 26599.8262 - val_mean_squared_error: 26599.8262\n",
      "Epoch 92/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25418.2832 - mean_squared_error: 25418.2832 - val_loss: 26507.1465 - val_mean_squared_error: 26507.1465\n",
      "Epoch 93/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25663.5566 - mean_squared_error: 25663.5566 - val_loss: 26520.6367 - val_mean_squared_error: 26520.6367\n",
      "Epoch 94/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25493.9160 - mean_squared_error: 25493.9160 - val_loss: 26629.7988 - val_mean_squared_error: 26629.7988\n",
      "Epoch 95/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25291.9238 - mean_squared_error: 25291.9238 - val_loss: 26515.5723 - val_mean_squared_error: 26515.5723\n",
      "Epoch 96/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25408.9258 - mean_squared_error: 25408.9258 - val_loss: 26574.6387 - val_mean_squared_error: 26574.6387\n",
      "Epoch 97/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25493.1973 - mean_squared_error: 25493.1973 - val_loss: 26611.9766 - val_mean_squared_error: 26611.9766\n",
      "Epoch 98/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25415.0684 - mean_squared_error: 25415.0684 - val_loss: 27302.7676 - val_mean_squared_error: 27302.7676\n",
      "Epoch 99/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25262.2109 - mean_squared_error: 25262.2109 - val_loss: 26630.5234 - val_mean_squared_error: 26630.5234\n",
      "Epoch 100/100\n",
      "\u001b[1m25737/25737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 25755.1582 - mean_squared_error: 25755.1582 - val_loss: 26517.4082 - val_mean_squared_error: 26517.4082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7de7172fc950>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "def build_model(hp):\n",
    "  \"\"\"\n",
    "    This function builds a sequential neural network model with hyperparameter tuning capabilities.\n",
    "\n",
    "    Args:\n",
    "    hp (HyperParameters): An instance of the HyperParameters class from Keras Tuner, \n",
    "                          used to define the search space for hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "    model (Sequential): A compiled Keras Sequential model with the following architecture:\n",
    "        - Input layer: Dense layer with units defined by hp.Int('units_1')\n",
    "        - Hidden layer: Dense layer with units defined by hp.Int('units_2')\n",
    "        - Output layer: Dense layer with 1 unit and linear activation\n",
    "\n",
    "    The model is compiled with:\n",
    "    - Optimizer: Adam with learning rate defined by hp.Choice('learning_rate')\n",
    "    - Loss function: Mean Squared Error\n",
    "    - Metrics: Mean Squared Error\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(hp.Int('units_1', min_value=32, max_value=128, step=32), input_shape=(input_shape,), activation='relu'))\n",
    "  model.add(Dense(hp.Int('units_2', min_value=32, max_value=128, step=32), activation='relu'))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "\n",
    "  model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                loss='mean_squared_error',\n",
    "                metrics=[MeanSquaredError()])\n",
    "  return model\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=10,  # Adjust the number of trials as needed\n",
    "    executions_per_trial=2,  # Optional: Run each trial multiple times\n",
    "    directory='my_dir',  # Optional: Specify a directory to save results\n",
    "    project_name='my_project'\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=Y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build the best model\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, Y_train, epochs=100, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3575/3575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step\n",
      "Mean Squared Error (MSE): 25709.01514511697\n",
      "Mean Absolute Error (MAE): 55.91713503547232\n",
      "R-squared: 0.17650920152664185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError, R2Score\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared:\", r2)\n",
    "ann_m = [mse, mae, r2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mse, mae, r2]\n",
      "Random forest: [14802.15123722491, 32.486672054971365, 0.5258692789469954] ,Training Time: 15m 75s\n",
      "NN (Keras): [25709.01514511697, 55.91713503547232, 0.17650920152664185] ,Training Time: 46m 52.1s\n"
     ]
    }
   ],
   "source": [
    "print(f'[mse, mae, r2]')\n",
    "print(f'Random forest: {rfr_m} ,Training Time: 15m 75s')\n",
    "print(f'NN (Keras): {ann_m} ,Training Time: 46m 52.1s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-introduction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
